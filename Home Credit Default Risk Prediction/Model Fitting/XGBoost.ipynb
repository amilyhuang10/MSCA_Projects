{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BP9rcsfrrgiN"
   },
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agvNGPdw5GaH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eS17m8pnBEu7"
   },
   "source": [
    "##### Original Data with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fufDGEwRjqVs",
    "outputId": "aa862c55-f6c0-47f4-82a9-e9bc1cb80c02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  52 tasks      | elapsed: 112.7min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 210.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=None,\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=42),\n",
       "             iid='deprecated', n_jobs=10,\n",
       "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5],\n",
       "                         'n_estimators': [100, 200, 300, 400]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Use AdaBoost Classifier along with GridSearchCV\n",
    "# Create a dictionary of parameters\n",
    "param_grid = {'n_estimators': [100, 200, 300, 400],\n",
    "              'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5]}\n",
    "\n",
    "# Create AdaBoost Classifier model\n",
    "abc = AdaBoostClassifier(random_state = 42)\n",
    "\n",
    "# Create GridSearch object with different combination of parameters\n",
    "abc_grid = GridSearchCV(abc, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs = 10, verbose = 5)\n",
    "\n",
    "# Fit GridSearch object with train data\n",
    "abc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4mJuYCH_gy3",
    "outputId": "dda01bce-66fb-497c-9014-8d8821c5e95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.5,\n",
      "                   n_estimators=400, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# b) Use the best estimator from GridSearchCV to predict on the test data\n",
    "# Identify the best performing model\n",
    "abc_bt = abc_grid.best_estimator_\n",
    "print(abc_bt)\n",
    "\n",
    "# Get predicted probabilities and predicted classes for data\n",
    "y_test_pred_abc = abc_bt.predict(X_test)\n",
    "y_train_pred_abc = abc_bt.predict(X_train) \n",
    "\n",
    "y_test_proba_abc = abc_bt.predict_proba(X_test)\n",
    "y_train_proba_abc = abc_bt.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTqeiZ1Z_iDH",
    "outputId": "c7b4c9c9-7f70-4cd8-f416-131c534c5aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix: \n",
      " [[223843     53]\n",
      " [ 19783     77]]\n",
      "Accuracy Train: 0.9186235415743612\n",
      "Precision Train: 0.5923076923076923\n",
      "Recall Train: 0.0038771399798590133\n",
      "AUC score 0.7120462854669866\n",
      "\n",
      " Test Confusion Matrix: \n",
      " [[55961    15]\n",
      " [ 4953    12]]\n",
      "Accuracy Test: 0.918478528412727\n",
      "Precision Test: 0.4444444444444444\n",
      "Recall Test: 0.002416918429003021\n",
      "AUC score 0.7104743710475256\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix: \\n\", skm.confusion_matrix(y_train, y_train_pred_abc))\n",
    "print(\"Accuracy Train:\", skm.accuracy_score(y_train, y_train_pred_abc))\n",
    "print(\"Precision Train:\", skm.precision_score(y_train, y_train_pred_abc))\n",
    "print(\"Recall Train:\", skm.recall_score(y_train, y_train_pred_abc))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_train, y_train_proba_abc[:,1]))\n",
    "\n",
    "print(\"\\n Test Confusion Matrix: \\n\", skm.confusion_matrix(y_test, y_test_pred_abc))\n",
    "print(\"Accuracy Test:\", skm.accuracy_score(y_test, y_test_pred_abc))\n",
    "print(\"Precision Test:\", skm.precision_score(y_test, y_test_pred_abc))\n",
    "print(\"Recall Test:\", skm.recall_score(y_test, y_test_pred_abc))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_test, y_test_proba_abc[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLSU1mbDxPTj"
   },
   "source": [
    "##### Under-sampling with AdaBoost with different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P810JGwPkODr",
    "outputId": "76b42156-bfbd-4a1e-88ba-ae26d20626b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 28.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=None,\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=42),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5],\n",
       "                         'n_estimators': [100, 200, 300, 400]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Use AdaBoost Classifier along with GridSearchCV\n",
    "# Create a dictionary of parameters\n",
    "param_grid1 = {'n_estimators': [100, 200, 300, 400],\n",
    "              'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5]}\n",
    "\n",
    "# Create AdaBoost Classifier model\n",
    "abc1 = AdaBoostClassifier(random_state = 42)\n",
    "\n",
    "# Create GridSearch object with different combination of parameters\n",
    "abc_grid1 = GridSearchCV(abc1, param_grid1, cv = 5, scoring = 'roc_auc',refit = True, n_jobs = -1, verbose = 5)\n",
    "\n",
    "# Fit GridSearch object with train data\n",
    "abc_grid1.fit(X_train_usm, y_train_usm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3LX4Pf3Pkjg",
    "outputId": "fea1cdad-24e9-45ae-c6b9-fc69a97c279b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.2,\n",
      "                   n_estimators=400, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# b) Use the best estimator from GridSearchCV to predict on the test data\n",
    "# Identify the best performing model\n",
    "abc_bt1 = abc_grid1.best_estimator_\n",
    "print(abc_bt1)\n",
    "\n",
    "# Get predicted probabilities and predicted classes for data\n",
    "y_test_pred_abc1 = abc_bt1.predict(X_test)\n",
    "y_train_pred_abc1 = abc_bt1.predict(X_train_usm) \n",
    "\n",
    "\n",
    "y_test_proba_abc1 = abc_bt1.predict_proba(X_test)\n",
    "y_train_proba_abc1 = abc_bt1.predict_proba(X_train_usm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WOy8Lt4PnAt",
    "outputId": "cd667c8c-406d-4665-f5f1-8bc0a1ca6971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix: \n",
      " [[13070  6790]\n",
      " [ 6972 12888]]\n",
      "Accuracy Train: 0.6535246727089628\n",
      "Precision Train: 0.6549446081918894\n",
      "Recall Train: 0.6489425981873111\n",
      "AUC score 0.7098312735979652\n",
      "\n",
      " Test Confusion Matrix: \n",
      " [[36689 19287]\n",
      " [ 1744  3221]]\n",
      "Accuracy Test: 0.6548957188099965\n",
      "Precision Test: 0.14310467389372666\n",
      "Recall Test: 0.6487411883182276\n",
      "AUC score 0.7073788277266289\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix: \\n\", skm.confusion_matrix(y_train_usm, y_train_pred_abc1))\n",
    "print(\"Accuracy Train:\", skm.accuracy_score(y_train_usm, y_train_pred_abc1))\n",
    "print(\"Precision Train:\", skm.precision_score(y_train_usm, y_train_pred_abc1))\n",
    "print(\"Recall Train:\", skm.recall_score(y_train_usm, y_train_pred_abc1))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_train_usm, y_train_proba_abc1[:,1]))\n",
    "\n",
    "print(\"\\n Test Confusion Matrix: \\n\", skm.confusion_matrix(y_test, y_test_pred_abc1))\n",
    "print(\"Accuracy Test:\", skm.accuracy_score(y_test, y_test_pred_abc1))\n",
    "print(\"Precision Test:\", skm.precision_score(y_test, y_test_pred_abc1))\n",
    "print(\"Recall Test:\", skm.recall_score(y_test, y_test_pred_abc1))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_test, y_test_proba_abc1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AeO4hbXKIg_O",
    "outputId": "c91a7cfb-e7e4-4f28-a019-5ce24fee28db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 52.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=None,\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=42),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.4, 0.5, 0.6, 0.7, 0.8],\n",
       "                         'n_estimators': [300, 400, 500, 600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Use AdaBoost Classifier along with GridSearchCV\n",
    "# Create a dictionary of parameters\n",
    "param_grid2 = {'n_estimators': [300, 400, 500, 600],\n",
    "              'learning_rate': [0.4, 0.5, 0.6, 0.7, 0.8]}\n",
    "\n",
    "# Create AdaBoost Classifier model\n",
    "abc2 = AdaBoostClassifier(random_state = 42)\n",
    "\n",
    "# Create GridSearch object with different combination of parameters\n",
    "abc_grid2 = GridSearchCV(abc2, param_grid2, cv = 5, scoring = 'roc_auc',refit = True, n_jobs = -1, verbose = 5)\n",
    "\n",
    "# Fit GridSearch object with train data\n",
    "abc_grid2.fit(X_train_usm, y_train_usm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NU9N5w0gI9VK",
    "outputId": "8cadc402-127f-4731-8875-fd11be6f59b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,\n",
      "                   n_estimators=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# b) Use the best estimator from GridSearchCV to predict on the test data\n",
    "# Identify the best performing model\n",
    "abc_bt2 = abc_grid2.best_estimator_\n",
    "print(abc_bt2)\n",
    "\n",
    "# Get predicted probabilities and predicted classes for data\n",
    "y_test_pred_abc2 = abc_bt2.predict(X_test)\n",
    "y_train_pred_abc2 = abc_bt2.predict(X_train_usm) \n",
    "\n",
    "\n",
    "y_test_proba_abc2 = abc_bt2.predict_proba(X_test)\n",
    "y_train_proba_abc2 = abc_bt2.predict_proba(X_train_usm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGe7u-1nJIbU",
    "outputId": "548a5c74-13f1-4ac4-b946-705847eb3a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix: \n",
      " [[13116  6744]\n",
      " [ 6902 12958]]\n",
      "Accuracy Train: 0.6564451158106748\n",
      "Precision Train: 0.6576997259161507\n",
      "Recall Train: 0.6524672708962739\n",
      "AUC score 0.7133951456773446\n",
      "\n",
      " Test Confusion Matrix: \n",
      " [[36741 19235]\n",
      " [ 1735  3230]]\n",
      "Accuracy Test: 0.6558966869595182\n",
      "Precision Test: 0.14377921210772313\n",
      "Recall Test: 0.6505538771399798\n",
      "AUC score 0.7075325297663896\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix: \\n\", skm.confusion_matrix(y_train_usm, y_train_pred_abc2))\n",
    "print(\"Accuracy Train:\", skm.accuracy_score(y_train_usm, y_train_pred_abc2))\n",
    "print(\"Precision Train:\", skm.precision_score(y_train_usm, y_train_pred_abc2))\n",
    "print(\"Recall Train:\", skm.recall_score(y_train_usm, y_train_pred_abc2))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_train_usm, y_train_proba_abc2[:,1]))\n",
    "\n",
    "print(\"\\n Test Confusion Matrix: \\n\", skm.confusion_matrix(y_test, y_test_pred_abc2))\n",
    "print(\"Accuracy Test:\", skm.accuracy_score(y_test, y_test_pred_abc2))\n",
    "print(\"Precision Test:\", skm.precision_score(y_test, y_test_pred_abc2))\n",
    "print(\"Recall Test:\", skm.recall_score(y_test, y_test_pred_abc2))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_test, y_test_proba_abc2[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pWysYs3rp58"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pnvbXq-CA2h"
   },
   "source": [
    "##### Original Data with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q72SDtEnr14y",
    "outputId": "7c2bf3f1-18d3-4d7c-e623-1cbdeb9afe2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 90.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_state=42, reg_alpha=0,\n",
       "                                           reg_lambda=1, s...\n",
       "       2.75, 3.  , 3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75, 5.  ]),\n",
       "                                        'learning_rate': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6]),\n",
       "                                        'max_depth': [1, 2],\n",
       "                                        'n_estimators': array([ 100,  150,  200,  250,  300,  350,  400,  450,  500,  550,  600,\n",
       "        650,  700,  750,  800,  850,  900,  950, 1000])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Use XGBoost Classifier along with RandomizedSearchCV\n",
    "# Create a dictionary of parameters\n",
    "param_grid3 = {'n_estimators': np.arange(100, 1050, 50),\n",
    "              'learning_rate': np.arange(0.1, 1.7, 0.1),\n",
    "               'max_depth':[1,2],\n",
    "               'gamma':np.arange(0, 5.25, 0.25)}\n",
    "\n",
    "# Create XGBoost Classifier model\n",
    "clf_xgb = xgb.XGBClassifier(random_state = 42)\n",
    "\n",
    "# Create GridSearch object with different combination of parameters\n",
    "xgb_grid = RandomizedSearchCV(clf_xgb, param_grid3, cv = 5, scoring = 'roc_auc',refit = True, n_jobs = -1, verbose = 5)\n",
    "\n",
    "# Fit GridSearch object with train data\n",
    "xgb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnYy9xHbtA3s",
    "outputId": "66c39f7f-5a7d-482f-d599-1757db22f609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=4.5,\n",
      "              learning_rate=1.4000000000000001, max_delta_step=0, max_depth=1,\n",
      "              min_child_weight=1, missing=None, n_estimators=550, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Use the best estimator from RandomizedSearchCV to predict on the test data\n",
    "# Identify the best performing model\n",
    "xgb_bt = xgb_grid.best_estimator_\n",
    "print(\"Best estimator:\", xgb_bt)\n",
    "\n",
    "# Get predicted probabilities and predicted classes\n",
    "y_test_pred_xgb = xgb_bt.predict(X_test)\n",
    "y_train_pred_xgb = xgb_bt.predict(X_train)\n",
    "\n",
    "y_test_proba_xgb = xgb_bt.predict_proba(X_test)\n",
    "y_train_proba_xgb = xgb_bt.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4gFiuxAr1p2",
    "outputId": "4e60b10c-4c88-4d9a-e704-2dab560fb1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix: \n",
      " [[223807     89]\n",
      " [ 19760    100]]\n",
      "Accuracy Train: 0.9185702095538161\n",
      "Precision Train: 0.5291005291005291\n",
      "Recall Train: 0.005035246727089627\n",
      "AUC score 0.7121650501459262\n",
      "\n",
      " Test Confusion Matrix: \n",
      " [[55956    20]\n",
      " [ 4951    14]]\n",
      "Accuracy Test: 0.9184293004709473\n",
      "Precision Test: 0.4117647058823529\n",
      "Recall Test: 0.0028197381671701913\n",
      "AUC score 0.7104054323526081\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix: \\n\", skm.confusion_matrix(y_train, y_train_pred_xgb))\n",
    "print(\"Accuracy Train:\", skm.accuracy_score(y_train, y_train_pred_xgb))\n",
    "print(\"Precision Train:\", skm.precision_score(y_train, y_train_pred_xgb))\n",
    "print(\"Recall Train:\", skm.recall_score(y_train, y_train_pred_xgb))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_train, y_train_proba_xgb[:,1]))\n",
    "\n",
    "print(\"\\n Test Confusion Matrix: \\n\", skm.confusion_matrix(y_test, y_test_pred_xgb))\n",
    "print(\"Accuracy Test:\", skm.accuracy_score(y_test, y_test_pred_xgb))\n",
    "print(\"Precision Test:\", skm.precision_score(y_test, y_test_pred_xgb))\n",
    "print(\"Recall Test:\", skm.recall_score(y_test, y_test_pred_xgb))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_test, y_test_proba_xgb[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8-6nSr7vAGI"
   },
   "source": [
    "##### Under-sampling with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOR7esNWr1Uo",
    "outputId": "92a0dbf8-ec6b-4377-b724-258ab1a059f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 12.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_state=42, reg_alpha=0,\n",
       "                                           reg_lambda=1, s...\n",
       "       2.75, 3.  , 3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75, 5.  ]),\n",
       "                                        'learning_rate': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6]),\n",
       "                                        'max_depth': [1, 2],\n",
       "                                        'n_estimators': array([ 100,  150,  200,  250,  300,  350,  400,  450,  500,  550,  600,\n",
       "        650,  700,  750,  800,  850,  900,  950, 1000])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use XGBoost Classifier along with RandomizedSearchCV\n",
    "# Create a dictionary of parameters\n",
    "param_grid4 = {'n_estimators': np.arange(100, 1050, 50),\n",
    "              'learning_rate': np.arange(0.1, 1.7, 0.1),\n",
    "               'max_depth':[1,2],\n",
    "               'gamma':np.arange(0, 5.25, 0.25)}\n",
    "\n",
    "# Create XGBoost Classifier model\n",
    "clf_xgb1 = xgb.XGBClassifier(random_state = 42)\n",
    "\n",
    "# Create GridSearch object with different combination of parameters\n",
    "xgb_grid1 = RandomizedSearchCV(clf_xgb1, param_grid4, cv = 5, scoring = 'roc_auc',refit = True, n_jobs = -1, verbose = 5)\n",
    "\n",
    "# Fit GridSearch object with train data\n",
    "xgb_grid1.fit(X_train_usm, y_train_usm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygZZ1hVJr052",
    "outputId": "ca96440c-0ff1-4970-c67a-1351e95b36d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0.5,\n",
      "              learning_rate=0.30000000000000004, max_delta_step=0, max_depth=1,\n",
      "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Use the best estimator from RandomizedSearchCV to predict on the test data\n",
    "# Identify the best performing model\n",
    "xgb_bt1 = xgb_grid1.best_estimator_\n",
    "print(\"Best estimator:\", xgb_bt1)\n",
    "\n",
    "# Get predicted probabilities and predicted classes\n",
    "y_test_pred_xgb1 = xgb_bt1.predict(X_test)\n",
    "y_train_pred_xgb1 = xgb_bt1.predict(X_train_usm)\n",
    "\n",
    "y_test_proba_xgb1 = xgb_bt1.predict_proba(X_test)\n",
    "y_train_proba_xgb1 = xgb_bt1.predict_proba(X_train_usm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3MrEzdFJRA6",
    "outputId": "abfb5ef5-c6e7-477b-9325-564649331c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix: \n",
      " [[13152  6708]\n",
      " [ 6973 12887]]\n",
      "Accuracy Train: 0.6555639476334341\n",
      "Precision Train: 0.657667772390916\n",
      "Recall Train: 0.6488922457200402\n",
      "AUC score 0.7126920239257887\n",
      "\n",
      " Test Confusion Matrix: \n",
      " [[36750 19226]\n",
      " [ 1746  3219]]\n",
      "Accuracy Test: 0.6558638683316651\n",
      "Precision Test: 0.1434172421474716\n",
      "Recall Test: 0.6483383685800604\n",
      "AUC score 0.7079848384165793\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix: \\n\", skm.confusion_matrix(y_train_usm, y_train_pred_xgb1))\n",
    "print(\"Accuracy Train:\", skm.accuracy_score(y_train_usm, y_train_pred_xgb1))\n",
    "print(\"Precision Train:\", skm.precision_score(y_train_usm, y_train_pred_xgb1))\n",
    "print(\"Recall Train:\", skm.recall_score(y_train_usm, y_train_pred_xgb1))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_train_usm, y_train_proba_xgb1[:,1]))\n",
    "\n",
    "print(\"\\n Test Confusion Matrix: \\n\", skm.confusion_matrix(y_test, y_test_pred_xgb1))\n",
    "print(\"Accuracy Test:\", skm.accuracy_score(y_test, y_test_pred_xgb1))\n",
    "print(\"Precision Test:\", skm.precision_score(y_test, y_test_pred_xgb1))\n",
    "print(\"Recall Test:\", skm.recall_score(y_test, y_test_pred_xgb1))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_test, y_test_proba_xgb1[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKnlxTkBADxJ"
   },
   "source": [
    "##### Cost-sensitive with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V589RIN-bFB",
    "outputId": "51dde979-adf0-4716-bda4-6f4f79f00878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 67.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_state=42, reg_alpha=0,\n",
       "                                           reg_lambda=1,\n",
       "                                           s...\n",
       "       2.75, 3.  , 3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75, 5.  ]),\n",
       "                                        'learning_rate': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6]),\n",
       "                                        'max_depth': [1, 2],\n",
       "                                        'n_estimators': array([ 100,  150,  200,  250,  300,  350,  400,  450,  500,  550,  600,\n",
       "        650,  700,  750,  800,  850,  900,  950, 1000])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Use XGBoost Classifier along with RandomizedSearchCV\n",
    "# Create a dictionary of parameters\n",
    "param_grid5 = {'n_estimators': np.arange(100, 1050, 50),\n",
    "              'learning_rate': np.arange(0.1, 1.7, 0.1),\n",
    "               'max_depth':[1,2],\n",
    "               'gamma':np.arange(0, 5.25, 0.25)}\n",
    "\n",
    "# Create XGBoost Classifier model\n",
    "clf_xgb2 = xgb.XGBClassifier(random_state = 42, scale_pos_weight = weight_1)\n",
    "\n",
    "# Create GridSearch object with different combination of parameters\n",
    "xgb_grid2 = RandomizedSearchCV(clf_xgb2, param_grid5, cv = 5, scoring = 'roc_auc',refit = True, n_jobs = -1, verbose = 5)\n",
    "\n",
    "# Fit GridSearch object with train data\n",
    "xgb_grid2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVX2D75v_Os4"
   },
   "outputs": [],
   "source": [
    "# Use the best estimator from RandomizedSearchCV to predict on the test data\n",
    "# Identify the best performing model\n",
    "xgb_bt2 = xgb_grid2.best_estimator_\n",
    "print(\"Best estimator:\", xgb_bt2)\n",
    "\n",
    "# Get predicted probabilities and predicted classes\n",
    "y_test_pred_xgb2 = xgb_bt2.predict(X_test)\n",
    "y_train_pred_xgb2 = xgb_bt2.predict(X_train)\n",
    "\n",
    "y_test_proba_xgb2 = xgb_bt2.predict_proba(X_test)\n",
    "y_train_proba_xgb2 = xgb_bt2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xh2BqOZU_h2y",
    "outputId": "94b68363-1dca-4374-e143-60314f301f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix: \n",
      " [[150956  72940]\n",
      " [  6762  13098]]\n",
      "Accuracy Train: 0.6730254845008944\n",
      "Precision Train: 0.15223505892745065\n",
      "Recall Train: 0.6595166163141994\n",
      "AUC score 0.727116094281797\n",
      "\n",
      " Test Confusion Matrix: \n",
      " [[37807 18169]\n",
      " [ 1780  3185]]\n",
      "Accuracy Test: 0.6726505964785612\n",
      "Precision Test: 0.14915238362836003\n",
      "Recall Test: 0.6414904330312186\n",
      "AUC score 0.7146429951060885\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix: \\n\", skm.confusion_matrix(y_train, y_train_pred_xgb2))\n",
    "print(\"Accuracy Train:\", skm.accuracy_score(y_train, y_train_pred_xgb2))\n",
    "print(\"Precision Train:\", skm.precision_score(y_train, y_train_pred_xgb2))\n",
    "print(\"Recall Train:\", skm.recall_score(y_train, y_train_pred_xgb2))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_train, y_train_proba_xgb2[:,1]))\n",
    "\n",
    "print(\"\\n Test Confusion Matrix: \\n\", skm.confusion_matrix(y_test, y_test_pred_xgb2))\n",
    "print(\"Accuracy Test:\", skm.accuracy_score(y_test, y_test_pred_xgb2))\n",
    "print(\"Precision Test:\", skm.precision_score(y_test, y_test_pred_xgb2))\n",
    "print(\"Recall Test:\", skm.recall_score(y_test, y_test_pred_xgb2))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_test, y_test_proba_xgb2[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaIfQBDCrKOs"
   },
   "source": [
    "Search weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHxEvNqsStJo",
    "outputId": "1dc99545-3147-4b5b-b384-46ebcfe6e232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 83.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_state=42, reg_alpha=0,\n",
       "                                           reg_lambda=1, s...\n",
       "                                        'learning_rate': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]),\n",
       "                                        'max_depth': [1, 2],\n",
       "                                        'n_estimators': array([ 100,  150,  200,  250,  300,  350,  400,  450,  500,  550,  600,\n",
       "        650,  700,  750,  800,  850,  900,  950, 1000]),\n",
       "                                        'scale_pos_weight': [4, 6, 8, 10,\n",
       "                                                             11.273716012084591,\n",
       "                                                             12, 14]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 0,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Use XGBoost Classifier along with RandomizedSearchCV\n",
    "# Create a dictionary of parameters\n",
    "param_grid6 = {'n_estimators': np.arange(100, 1050, 50),\n",
    "              'learning_rate': np.arange(0.01, 0.1, 0.01),\n",
    "               'max_depth':[1,2],\n",
    "               'gamma':np.arange(0, 5.25, 0.25),\n",
    "               'scale_pos_weight': [4, 6, 8, 10, 11.273716012084591, 12, 14]}\n",
    "\n",
    "# Create XGBoost Classifier model\n",
    "clf_xgb3 = xgb.XGBClassifier(random_state = 42)\n",
    "\n",
    "# Create GridSearch object with different combination of parameters\n",
    "xgb_grid3 = RandomizedSearchCV(clf_xgb3, param_grid6, cv = 5, scoring = 'roc_auc',refit = True, n_jobs = -1, verbose = 5)\n",
    "\n",
    "# Fit GridSearch object with train data\n",
    "xgb_grid3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9TV5xZrhURaW",
    "outputId": "830b6780-e9a1-4586-eae4-8a5343e6490d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=4.25,\n",
      "              learning_rate=0.06999999999999999, max_delta_step=0, max_depth=2,\n",
      "              min_child_weight=1, missing=None, n_estimators=700, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=6, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Use the best estimator from RandomizedSearchCV to predict on the test data\n",
    "# Identify the best performing model\n",
    "xgb_bt3 = xgb_grid3.best_estimator_\n",
    "print(\"Best estimator:\", xgb_bt3)\n",
    "\n",
    "# Get predicted probabilities and predicted classes\n",
    "y_test_pred_xgb3 = xgb_bt3.predict(X_test)\n",
    "y_train_pred_xgb3 = xgb_bt3.predict(X_train)\n",
    "\n",
    "y_test_proba_xgb3 = xgb_bt3.predict_proba(X_test)\n",
    "y_train_proba_xgb3 = xgb_bt3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eW5iukRjUc33",
    "outputId": "9863e081-1004-4afb-e578-05c9a59943b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix: \n",
      " [[200190  23706]\n",
      " [ 13158   6702]]\n",
      "Accuracy Train: 0.8487667995864717\n",
      "Precision Train: 0.22040252565114443\n",
      "Recall Train: 0.3374622356495468\n",
      "AUC score 0.7218098361314782\n",
      "\n",
      " Test Confusion Matrix: \n",
      " [[50064  5912]\n",
      " [ 3325  1640]]\n",
      "Accuracy Test: 0.8484271672601369\n",
      "Precision Test: 0.21716101694915255\n",
      "Recall Test: 0.33031218529707956\n",
      "AUC score 0.7142888672904126\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix: \\n\", skm.confusion_matrix(y_train, y_train_pred_xgb3))\n",
    "print(\"Accuracy Train:\", skm.accuracy_score(y_train, y_train_pred_xgb3))\n",
    "print(\"Precision Train:\", skm.precision_score(y_train, y_train_pred_xgb3))\n",
    "print(\"Recall Train:\", skm.recall_score(y_train, y_train_pred_xgb3))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_train, y_train_proba_xgb3[:,1]))\n",
    "\n",
    "print(\"\\n Test Confusion Matrix: \\n\", skm.confusion_matrix(y_test, y_test_pred_xgb3))\n",
    "print(\"Accuracy Test:\", skm.accuracy_score(y_test, y_test_pred_xgb3))\n",
    "print(\"Precision Test:\", skm.precision_score(y_test, y_test_pred_xgb3))\n",
    "print(\"Recall Test:\", skm.recall_score(y_test, y_test_pred_xgb3))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_test, y_test_proba_xgb3[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZDorFoOrOv-"
   },
   "source": [
    "Search learning rate with weight 11.273716012084591\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFAtD3hSqrEs",
    "outputId": "e5ae676e-faaf-4c2a-f3fb-2d5fc3bca4f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 80.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_state=42, reg_alpha=0,\n",
       "                                           reg_lambda=1,\n",
       "                                           s...\n",
       "       2.75, 3.  , 3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75, 5.  ]),\n",
       "                                        'learning_rate': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6]),\n",
       "                                        'max_depth': [1, 2],\n",
       "                                        'n_estimators': array([ 100,  150,  200,  250,  300,  350,  400,  450,  500,  550,  600,\n",
       "        650,  700,  750,  800,  850,  900,  950, 1000])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Use XGBoost Classifier along with RandomizedSearchCV\n",
    "# Create a dictionary of parameters\n",
    "param_grid7 = {'n_estimators': np.arange(100, 1050, 50),\n",
    "              'learning_rate': np.arange(0.01, 0.1, 0.01),\n",
    "               'max_depth':[1,2],\n",
    "               'gamma':np.arange(0, 5.25, 0.25)}\n",
    "\n",
    "# Create XGBoost Classifier model\n",
    "clf_xgb4 = xgb.XGBClassifier(random_state = 42, scale_pos_weight = weight_1)\n",
    "\n",
    "# Create GridSearch object with different combination of parameters\n",
    "xgb_grid4 = RandomizedSearchCV(clf_xgb4, param_grid5, cv = 5, scoring = 'roc_auc',refit = True, n_jobs = -1, verbose = 5)\n",
    "\n",
    "# Fit GridSearch object with train data\n",
    "xgb_grid4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dT6okiTNq4K_",
    "outputId": "e1330152-46c3-4119-fe25-ca410df2c72b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=2.5,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
      "              min_child_weight=1, missing=None, n_estimators=550, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=11.273716012084591,\n",
      "              seed=None, silent=None, subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Use the best estimator from RandomizedSearchCV to predict on the test data\n",
    "# Identify the best performing model\n",
    "xgb_bt4 = xgb_grid4.best_estimator_\n",
    "print(\"Best estimator:\", xgb_bt4)\n",
    "\n",
    "# Get predicted probabilities and predicted classes\n",
    "y_test_pred_xgb4 = xgb_bt4.predict(X_test)\n",
    "y_train_pred_xgb4 = xgb_bt4.predict(X_train)\n",
    "\n",
    "y_test_proba_xgb4 = xgb_bt4.predict_proba(X_test)\n",
    "y_train_proba_xgb4 = xgb_bt4.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zriy9-cerByY",
    "outputId": "c27cc4a6-f12c-40aa-cb3f-0599b803b6f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix: \n",
      " [[150340  73556]\n",
      " [  6841  13019]]\n",
      "Accuracy Train: 0.670174272633289\n",
      "Precision Train: 0.15037828472422754\n",
      "Recall Train: 0.6555387713997985\n",
      "AUC score 0.7231947058591546\n",
      "\n",
      " Test Confusion Matrix: \n",
      " [[37638 18338]\n",
      " [ 1766  3199]]\n",
      "Accuracy Test: 0.6701071528199406\n",
      "Precision Test: 0.14853507916608627\n",
      "Recall Test: 0.6443101711983887\n",
      "AUC score 0.7143377391202475\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix: \\n\", skm.confusion_matrix(y_train, y_train_pred_xgb4))\n",
    "print(\"Accuracy Train:\", skm.accuracy_score(y_train, y_train_pred_xgb4))\n",
    "print(\"Precision Train:\", skm.precision_score(y_train, y_train_pred_xgb4))\n",
    "print(\"Recall Train:\", skm.recall_score(y_train, y_train_pred_xgb4))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_train, y_train_proba_xgb4[:,1]))\n",
    "\n",
    "print(\"\\n Test Confusion Matrix: \\n\", skm.confusion_matrix(y_test, y_test_pred_xgb4))\n",
    "print(\"Accuracy Test:\", skm.accuracy_score(y_test, y_test_pred_xgb4))\n",
    "print(\"Precision Test:\", skm.precision_score(y_test, y_test_pred_xgb4))\n",
    "print(\"Recall Test:\", skm.recall_score(y_test, y_test_pred_xgb4))\n",
    "print(\"AUC score\", skm.roc_auc_score(y_test, y_test_proba_xgb4[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzpPt2LNQhrk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vhuCB-MZZOdM",
    "AdWyZZ13m1U3",
    "PKwCvmvOnE0Q",
    "Ox8ecO6ynLrO",
    "5rfCaRrL9DqO",
    "1Umb9Y73yFiy",
    "0mjIaTxbBDER",
    "mo5F69_qo0zt",
    "c_H2_anIJd9Z",
    "5G35u9QNXSJy",
    "E6Hx3_1Ms_il",
    "BbeOgWrfs7E_",
    "fsmVIShsuwHA",
    "BjR6GEy6u0Uo",
    "e7kaDbcPzG1g",
    "88T0jjxRzJ7v",
    "TIYH1Un0HLTt",
    "2DOApvg0G53g",
    "64iE7RY3HBN4"
   ],
   "name": "EDA_Feature_Engineering_XGBoost_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
